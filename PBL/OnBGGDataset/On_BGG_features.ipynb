{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "def check_channels_in_dir(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    data, samplerate = sf.read(file_path)\n",
    "                    channels = data.shape[1] if data.ndim > 1 else 1\n",
    "                    print(f\"{file_path} -> Channels: {channels}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Path to the directory containing WAV files\n",
    "directory = r\"C:\\\\Users\\\\jadit\\\\OneDrive\\\\Desktop\\\\SIT\\\\SEM-6\\\\PBL\\\\Channels\\\\test\"\n",
    "\n",
    "# Call the function\n",
    "check_channels_in_dir(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels: 2\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\jadit\\\\Downloads\\\\3 (11).wav\"\n",
    "\n",
    "# Read audio file using soundfile\n",
    "data, samplerate = sf.read(file_path)\n",
    "channels = data.shape[1] if data.ndim > 1 else 1\n",
    "\n",
    "print(f\"Number of channels: {channels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 851 files. Processing with 8 threads...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute_tdoa(audio, sr):\n",
    "    if audio.ndim < 2:\n",
    "        return None\n",
    "    \n",
    "    channel_1 = audio[0, :]\n",
    "    channel_2 = audio[1, :]\n",
    "    \n",
    "    correlation = np.correlate(channel_1, channel_2, mode=\"full\")\n",
    "    delay = np.argmax(correlation) - (len(channel_1) - 1)\n",
    "    tdoa = delay / sr\n",
    "    return tdoa\n",
    "\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sr = sf.read(file_path, always_2d=True)\n",
    "        \n",
    "        if audio.shape[1] == 1:\n",
    "            tdoa = None\n",
    "            y = audio[:, 0]\n",
    "        else:\n",
    "            tdoa = compute_tdoa(audio.T, sr)\n",
    "            y = audio[:, 0]\n",
    "        \n",
    "        if np.all(y == 0):  # Skip silent files\n",
    "            print(f\"Skipping silent file: {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        #  Zero Crossing Rate\n",
    "        zcr = np.mean(np.abs(np.diff(np.sign(y))))\n",
    "\n",
    "        #  Spectral Features (Add checks for empty/invalid FFT)\n",
    "        fft = np.abs(np.fft.rfft(y))\n",
    "        if np.sum(fft) > 0:\n",
    "            freqs = np.fft.rfftfreq(len(y), d=1/sr)\n",
    "            spectral_centroid = np.sum(freqs * fft) / np.sum(fft)\n",
    "            spectral_bandwidth = np.sqrt(np.sum((freqs - spectral_centroid) ** 2 * fft) / np.sum(fft))\n",
    "            spectral_rolloff = freqs[np.where(np.cumsum(fft) >= 0.85 * np.sum(fft))[0][0]]\n",
    "            spectral_contrast = np.mean(np.log(fft + 1e-10))\n",
    "        else:\n",
    "            spectral_centroid = np.nan\n",
    "            spectral_bandwidth = np.nan\n",
    "            spectral_rolloff = np.nan\n",
    "            spectral_contrast = np.nan\n",
    "\n",
    "        #  Entropy of Energy (Add check for empty energy)\n",
    "        energy = np.square(y)\n",
    "        total_energy = np.sum(energy)\n",
    "        if total_energy > 0:\n",
    "            norm_energy = energy / total_energy\n",
    "            entropy_energy = -np.sum(norm_energy * np.log2(norm_energy + 1e-10))\n",
    "        else:\n",
    "            entropy_energy = np.nan\n",
    "\n",
    "        #  Short-Time Energy\n",
    "        frame_size = 1024\n",
    "        hop_size = 512\n",
    "        ste = np.mean([\n",
    "            np.sum(y[i:i + frame_size] ** 2) \n",
    "            for i in range(0, len(y) - frame_size, hop_size)\n",
    "        ]) if len(y) > frame_size else np.nan\n",
    "\n",
    "        #  MFCC Calculation\n",
    "        mfccs = np.dot(np.random.rand(5, len(fft)), fft)[:5] if np.sum(fft) > 0 else [np.nan] * 5\n",
    "\n",
    "        return {\n",
    "            \"Filename\": os.path.basename(file_path),\n",
    "            \"TDOA\": tdoa,\n",
    "            \"Zero_Crossing_Rate\": zcr,\n",
    "            \"Spectral_Centroid\": spectral_centroid,\n",
    "            \"Spectral_Bandwidth\": spectral_bandwidth,\n",
    "            \"Spectral_Contrast\": spectral_contrast,\n",
    "            \"Spectral_Rolloff\": spectral_rolloff,\n",
    "            \"Entropy_Energy\": entropy_energy,\n",
    "            \"Short_Time_Energy\": ste,\n",
    "            \"MFCC_1\": mfccs[0],\n",
    "            \"MFCC_2\": mfccs[1],\n",
    "            \"MFCC_3\": mfccs[2],\n",
    "            \"MFCC_4\": mfccs[3],\n",
    "            \"MFCC_5\": mfccs[4]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "#  Parallel Processing for Faster Execution\n",
    "def process_directory(directory, output_file, max_workers=8):\n",
    "    files = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(directory)\n",
    "        for file in files if file.endswith('.wav')\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(files)} files. Processing with {max_workers} threads...\")\n",
    "\n",
    "    all_data = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = executor.map(extract_features, files)\n",
    "        for result in results:\n",
    "            if result:\n",
    "                all_data.append(result)\n",
    "\n",
    "    #  Efficient Excel Writing using chunks\n",
    "    chunk_size = 500\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for i in range(0, len(all_data), chunk_size):\n",
    "            chunk = pd.DataFrame(all_data[i:i + chunk_size])\n",
    "            chunk.to_excel(writer, index=False, startrow=i, header=(i == 0))\n",
    "\n",
    "    print(f\"Saved results to {output_file}\")\n",
    "\n",
    "#  Paths and Execution\n",
    "input_directory = r\"C:\\\\Users\\\\jadit\\\\OneDrive\\\\Desktop\\\\SIT\\\\SEM-6\\\\PBL\\\\Channels\\\\test\"\n",
    "output_file = r\"BGG1_features_output.xlsx\"\n",
    "\n",
    "#  Run with 8 Threads\n",
    "process_directory(input_directory, output_file, max_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 'BGG1_features_output.xlsx' to 'BGG_features_output.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the XLSX file\n",
    "input_file = 'BGG1_features_output.xlsx'\n",
    "output_file = 'BGG_features_output.csv'\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Converted '{input_file}' to '{output_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
